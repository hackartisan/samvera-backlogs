dzi
Creating all tiles and pushing them to S3 with rake chf:dzi:push_all takes about 7 hours on staging, estimated about 9 on production. Things left to do     mess with resque workers and roles, so the new box we set up for this purpose only does DZI's, and the old box does the old tasks (that may not be able to run on a separate server without shared FS,our new job can)    rake tasks to clean orphans in s3, or clear all.    we can do some clever stuff in the JS to fall back to hydra-derivative thumb if OSD isn't available. Likely with a "Sorry, zooming not currently available" message.  That can actually work for canteloupe or any other server too, we can do this in master.    Set at S3 HTTP caching headers.    Make rake task to set CORS and any other setup on S3 bucket.    Consider CDN. Individual tiles from S3 are coming back in like 40-70ms. Could a CDN make that even faster?. CDN could also gzip which would prob make it faster. (Or we could figure out if there's a way to deliver gzip'd response just from S3, probably by storing gzipped, possibly in addition to non-gzipped).  decided ignore for now    Note we have no auth at present. There are possibilities. Discuss. Currently all tiles are put in S3 such that they are publicly available. Maybe: No auth, document very clearly. investigate robots.txt on s3.  leave notes on plan for auth if we need it. for now decided not to auth    Mess with number-of-layers in DZI and/or other generation params to see if we can stop the "come in a block at a time" thing, and get it back to "come in blurry then get sharper" updated openseadragon to latest for now, that's pretty much all we can do without intensive debugging/enhancement of OSD.    Ramelli show page is taking a long time to come in again. Did some refactoring changes I made effect performance? Or maybe OSD is being loaded too soon, and taking browser CPU time? Time for some more profiling. (Could not reproduce, guess is the app machine was just busy. all image requests go through rails app, which is unfortunate but not part of this issue).    Docs on dzi setup:  rake tasks, env variables, auth options.    Infrastructure setup  For both production and staging, we need (so two of each of these, one prod one stage):  An EC2 box for 'jobs', with app_role jobs set in local_env.yml  Ideally gets a hostnaem not just numeric IP to avoid confusion needs vips installed, compiled so it can read TIFF and dzsave will prob need GraphicsMagick in the future, so might as well if it's easy The 'jobs' box does not need redis or httpd/passenger running. Would leave more resources for jobs if they were not running. And does not need ports 80/443 open. The 'jobs' box needs /opt/sufia-project/shared/config/redis.yml set to proper redis server (which is currently app server) IP address, not 127.0.0.1 which is not accurate. Might be easier and avoid confusing to just do this on all boxes, jobs server doens't really need special config if they all have a valid internal ip that can be reached?   An S3 bucket. Perhaps chf-dzi-prod and chf-dzi-stage, matching the "service_level"/srv_lvl keys being used to avoid confusing. AWS access key set with write permissions to the appropriate bucket (one prod one stage)   new local_env.yml keys. Values will be different in prod vs staging. While some of these keys will only be used on certain 'roles', I think it makes sense just to give them to all machines for simplicity and consistency and not having to keep tweaking it if we discover we need a key on a role we didn't expect. (Our manual tweaks are pretty error-prone, best to do it and leave it).  aws_access_key_id: $appropriate_id aws_secret_access_key: $appropriate_key dzi_s3_bucket: $appropriate_bucket_name image_server_on_viewer: dzi_s3   Ideally this is all done in an automated fashion eg ansible. As we get more servers in our fleet, it is very easy for manual editing to result in inconsistencies between machines, resulting in time-consuming bugs. Minimizing any manual editing would be great.     reindex on prod (can be done before merge, new index is in master)    Create all DZI tiles on prod. I would probably deploy to prod first -- all viewers will show up with new "sorry, zooming not available" error, which is great, until the dzi's are created, then they'll start working as they are created. Then run rake chf:dzi:push_all on the new jobs server, properly env-configured as above.