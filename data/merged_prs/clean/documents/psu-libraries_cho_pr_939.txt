UTF-8 validation
Description Previously if an invalid UTF-8 character was entered, it would result in a 500 error. Now we scan for these invalid characters; if any are detected, they are replaced with a ðŸ’© (lol) and returned back to the user with a helpful error message asking them to make the necessary changes. Additionally, there is one valid UTF-8 character that is not acceptable by Postgresâ€”this character is also detected and ðŸ’©'d. Please note, however, that this only detects truly invalid UTF-8 characters that would cause a crash. If someone copy-and-pasted something from an old version of MS Word that contained the phrase "it's" in some weird encoding, and was represented as "itÃ¢â‚¬â„¢s" in UTF-8, we do not flag this, because all of the characters are indeed valid even if unintentionally weirdâ€”unintentionally weird being rather difficult to detect automatically by a computer. Please also note that it's really hard / borderline impossible to actually test this through a modern browser like Chrome which tends to do the right thing most of the time. I tried to generate invalid UTF-8 characters myself and paste them into the Chrome input fields, and they were replaced with the "ï¿½" when pasted into the field. Â¯_(ãƒ„)_/Â¯ Connected to #93 Changes  Development and Production data dictionary currently get the new UTF-8 validator on the following fields: title, subject, location, description, acknowledgments, narrative