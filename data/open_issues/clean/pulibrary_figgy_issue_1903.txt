Resumable reindex
Reindexing all of figgy takes about 7 hours and frequently fails along the way due to solr connection errors. it needs to either be more tolerant or resumable.
Would it be possible to break this up into batches?  e.g., the initial task just lists records, and then spins off background jobs for each batch of 100 (or 1000 or whatever grouping makes sense) of records?  That would allow each batch to succeed or fail, and then be retried automatically.  I don't know if it's practcial to pass 100 or 1000 ids to a job, however.  Another strategy I've used to break up large Solr reindexing jobs was to reindex groups of records, listing the oldest 1000 records that were older than a given timestamp.  With the reindexer stopping only when there were no more records older than the timestamp.
these both seem like good ideas. the timestamp-based one seems more immediately helpful to me since i've gotten halfway through the index already. so i guess i'll try that one.