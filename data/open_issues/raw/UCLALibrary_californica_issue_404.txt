Load placeholder "Image Not Available" Tiff Images for Corrupt LADNN Tiffs
Given that a number of LADNN images did not load because the TIFF files were corrupt, please load this placeholder TIFF image in place of the actual image. You can retrieve filenames from this spreadsheet: https://docs.google.com/spreadsheets/d/1i8lGryerGo064d4r9FAUrqrARxbhcHkEKKXlRnLqoeY/edit?usp=sharing Acceptance Criteria:   A temporary TIFF and thumbnail are in place for all corrupt images so that users (and project team members) are assured that we are aware the files are not available  Related to UCLALibrary/amalgamated-samvera#263
Placeholder tiff image is currently available here: https://ucla.box.com/s/nt6j65jum6ljrpbsa0qoji7nmwwhefm4 name of file: image_not_available.tif
List of files from Bess's unix command that are not true Tiff files: https://gist.github.com/bess/54920a54f7a873c2f273d6d6bb29d901
The following tiffs appear on Bess's list and were in the data set, but are not part of the collection. uclamss_1387_14984-09.tif uclamss_1379_15037-01.tif  Why might that happen. Sometimes duplicates or bad images were digitized and loaded into DLCS, but later removed from the collection. Usually these files are removed from the masters directory, but it's possible they were not. In both cases, I verified inn DLCS staff that the there was no record of that local ID. I also verified that the file did exist on dlmasters, which it does.   That means when we copied all the masters for LADNN we would have also copied this TIFF. I assume that Bess's script ran against the staging location for the ingest and not the actually ingested files. (Which is fine -- just documenting my assumptions.)
As to @emcaulay's question above, I have no idea why that would happen. Those images are in the folder, but I guess they aren't referenced in the CSV spreadsheet. I do not have an answer to that.
Here are some concerns:  1. If we just replace the tiff for the affected objects as they're loaded right now (e.g., via a batch update job), we will have to re-run that job if we re-ingest the content (which we're likely to have to do at least once b/c of the ARK update story). That isn't a deal-breaker, I just want us to understand that we're committing to that, and that it's a piece of knowledge we'll have to pass forward to anyone who is maintaining this system. 2. We are going to have TIFFs in our system that are not the actual expected archival object, but no way of easily identifying that these are incomplete objects. Could we also include some kind of metadata flag that lets us know when an object does not actually contain the expected content? Otherwise, over time, how will we know how many objects in our repository do not actually contain their expected content? We can't just expect to track that from a list that's attached to a waffle ticket forever.  My approach to this would be: 1. Make a CSV that only contains rows for the records that have corrupted tiffs, and for each of these rows replace the referenced TIFF with the placeholder. Also include some yet to be decided upon metadata field that will let us easily find all of these objects later.  2. Run that CSV through a cleaner job that I wrote already, which will delete the objects that match on the ARK. 3. Run that CSV through the importer, which will re-create these objects, this time with their special "this object is missing its payload" metadata and the placeholder tiff attached.  I am open to suggestions about what the metadata flag should be for these.